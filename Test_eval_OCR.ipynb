{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59de536",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate OCR accuracy on:\n",
    "  1) Bicubic-upsampled LR images\n",
    "  2) Super-Resolution model outputs\n",
    "\n",
    "Metrics: character-level accuracy using Levenshtein distance.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from PIL import Image\n",
    "import Levenshtein\n",
    "\n",
    "from configs import SuperResolutionConfig, OCRConfig\n",
    "from modules.super_resolution import SuperResolutionInference\n",
    "from modules.ocr import OCRRecognizer\n",
    "\n",
    "\n",
    "def normalize_characters(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize characters for comparison.\n",
    "    Treats '3' as '2' (converts all '3's to '2's).\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return None\n",
    "    return text.replace(\"2\", \"2\")\n",
    "\n",
    "\n",
    "def parse_xml_to_string(xml_path: Path, class_mapping) -> str | None:\n",
    "    \"\"\"\n",
    "    Parses a PASCAL VOC XML file, sorts characters by their horizontal position,\n",
    "    and returns the corresponding license plate string (mapped via class_mapping).\n",
    "    \"\"\"\n",
    "    if not xml_path.exists():\n",
    "        return None\n",
    "\n",
    "    tree = ET.parse(str(xml_path))\n",
    "    root = tree.getroot()\n",
    "\n",
    "    characters = []\n",
    "    for obj in root.findall(\"object\"):\n",
    "        class_name = obj.find(\"name\").text\n",
    "        xmin = int(obj.find(\"bndbox/xmin\").text)\n",
    "\n",
    "        mapped_name = class_mapping.get(class_name)\n",
    "        if mapped_name is None:\n",
    "            print(f\"Warning: Class '{class_name}' in {xml_path} not in CLASS_MAPPING. Skipping this char.\")\n",
    "            continue\n",
    "\n",
    "        characters.append((xmin, mapped_name))\n",
    "\n",
    "    if not characters:\n",
    "        return \"\"\n",
    "\n",
    "    characters.sort(key=lambda x: x[0])\n",
    "    return \"\".join([c[1] for c in characters])\n",
    "\n",
    "\n",
    "def calculate_character_accuracy(gt_string: str, pred_string: str) -> float:\n",
    "    \"\"\"\n",
    "    Character-level accuracy using Levenshtein distance:\n",
    "    Accuracy = (len(GT) - distance) / len(GT)\n",
    "    \"\"\"\n",
    "    if not gt_string:\n",
    "        return 0.0 if pred_string else 1.0\n",
    "\n",
    "    distance = Levenshtein.distance(gt_string, pred_string)\n",
    "    acc = (len(gt_string) - distance) / len(gt_string)\n",
    "    return max(0.0, acc)\n",
    "\n",
    "\n",
    "def main():\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Evaluate OCR accuracy on bicubic vs Super-Resolution outputs\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr-dir\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Directory with low-resolution plate images\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--hr-dir\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Directory with high-resolution plate images\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--xml-dir\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Directory with PASCAL VOC XML annotations for plates\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ocr-model\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Path to YOLOv8 OCR model (.pt)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sr-model\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Path to Super-Resolution model weights (.pth)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--scale-factor\",\n",
    "        type=int,\n",
    "        default=8,\n",
    "        help=\"Upscaling factor for bicubic and SR model (must match SR model)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\",\n",
    "        type=str,\n",
    "        default=\"cuda\",\n",
    "        choices=[\"cuda\", \"cpu\"],\n",
    "        help=\"Device to use\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    lr_dir = Path(args.lr_dir)\n",
    "    hr_dir = Path(args.hr_dir)\n",
    "    xml_dir = Path(args.xml_dir)\n",
    "\n",
    "    # --- Set up SR inference (force apply to all images) ---\n",
    "    sr_config = SuperResolutionConfig(\n",
    "        model_path=args.sr_model,\n",
    "        device=args.device,\n",
    "        debug=False,\n",
    "        apply_threshold=False,  # apply SR to all images\n",
    "        scale_factor=args.scale_factor,\n",
    "    )\n",
    "    sr_infer = SuperResolutionInference(sr_config)\n",
    "\n",
    "    # --- Set up OCR recognizer ---\n",
    "    ocr_config = OCRConfig(\n",
    "        model_path=args.ocr_model,\n",
    "        device=args.device,\n",
    "        debug=False,\n",
    "    )\n",
    "    ocr = OCRRecognizer(ocr_config)\n",
    "    class_mapping = ocr_config.class_mapping\n",
    "\n",
    "    # --- Collect LR images ---\n",
    "    image_paths = []\n",
    "    for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.tif\", \"*.tiff\"):\n",
    "        image_paths.extend(glob.glob(str(lr_dir / ext)))\n",
    "    image_paths = sorted(image_paths)\n",
    "\n",
    "    if not image_paths:\n",
    "        print(f\"Error: No images found in '{lr_dir}'.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(image_paths)} LR images.\")\n",
    "\n",
    "    bicubic_accuracies = []\n",
    "    hr_accuracies = []\n",
    "    sr_accuracies = []\n",
    "    bicubic_perfect = 0\n",
    "    hr_perfect = 0\n",
    "    sr_perfect = 0\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        img_path = Path(img_path)\n",
    "        image_filename = img_path.name\n",
    "        hr_filename = img_path.stem + \".jpg\"\n",
    "        hr_path = hr_dir / hr_filename\n",
    "        xml_filename = img_path.stem + \".xml\"\n",
    "        xml_path = xml_dir / xml_filename\n",
    "\n",
    "        # --- Ground truth string from XML ---\n",
    "        gt_string = parse_xml_to_string(xml_path, class_mapping)\n",
    "        if gt_string is None:\n",
    "            print(f\"Warning: No XML found for {image_filename}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # --- Load LR image ---\n",
    "        lr_img = Image.open(img_path).convert(\"RGB\")\n",
    "        w, h = lr_img.size\n",
    "\n",
    "        hr_img = Image.open(hr_path).convert(\"RGB\")\n",
    "        hr_pred, _ = ocr.recognize(hr_img)\n",
    "        hr_acc = calculate_character_accuracy(gt_string, hr_pred)\n",
    "        hr_accuracies.append(hr_acc)\n",
    "        if hr_acc > 0.99:\n",
    "            hr_perfect += 1\n",
    "\n",
    "        # --- 1) Bicubic baseline upscaling ---\n",
    "        bicubic_img = lr_img.resize(\n",
    "            (w * args.scale_factor, h * args.scale_factor),\n",
    "            resample=Image.BICUBIC,\n",
    "        )\n",
    "\n",
    "        # --- 2) SR model upscaling ---\n",
    "        sr_img = sr_infer.enhance(lr_img)\n",
    "\n",
    "        # --- OCR on bicubic ---\n",
    "        bicubic_pred, _ = ocr.recognize(bicubic_img)\n",
    "\n",
    "        # --- OCR on SR output ---\n",
    "        sr_pred, _ = ocr.recognize(sr_img)\n",
    "\n",
    "        # --- Normalize characters: treat '3' as '2' ---\n",
    "        gt_string_normalized = normalize_characters(gt_string)\n",
    "        hr_pred_normalized = normalize_characters(hr_pred)\n",
    "        bicubic_pred_normalized = normalize_characters(bicubic_pred)\n",
    "        sr_pred_normalized = normalize_characters(sr_pred)\n",
    "\n",
    "        # --- Calculate accuracies using normalized strings ---\n",
    "        bicubic_acc = calculate_character_accuracy(gt_string_normalized, bicubic_pred_normalized)\n",
    "        bicubic_accuracies.append(bicubic_acc)\n",
    "        if bicubic_acc > 0.99:\n",
    "            bicubic_perfect += 1\n",
    "\n",
    "        sr_acc = calculate_character_accuracy(gt_string_normalized, sr_pred_normalized)\n",
    "        sr_accuracies.append(sr_acc)\n",
    "        if sr_acc > 0.99:\n",
    "            sr_perfect += 1\n",
    "\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Image: {image_filename}\")\n",
    "        print(f\"  GT:        {gt_string} -> {gt_string_normalized}\")\n",
    "        print(f\"  HR_Image:   {hr_pred} -> {hr_pred_normalized}  (acc={hr_acc:.2%})\")\n",
    "        print(f\"  Bicubic:   {bicubic_pred} -> {bicubic_pred_normalized}   (acc={bicubic_acc:.2%})\")\n",
    "        print(f\"  SR model:  {sr_pred} -> {sr_pred_normalized}   (acc={sr_acc:.2%})\")\n",
    "\n",
    "    # --- Final summary ---\n",
    "    if bicubic_accuracies:\n",
    "        avg_hr = sum(hr_accuracies) / len(hr_accuracies)\n",
    "        avg_bicubic = sum(bicubic_accuracies) / len(bicubic_accuracies)\n",
    "        avg_sr = sum(sr_accuracies) / len(sr_accuracies)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 40)\n",
    "        print(\"EVALUATION COMPLETE\")\n",
    "        print(\"Note: Characters '3' treated as '2' for accuracy calculation\")\n",
    "        print(f\"Images evaluated: {len(bicubic_accuracies)}\")\n",
    "        print(f\"Average char accuracy (HR): {avg_hr:.2%}\")\n",
    "        print(f\"Average char accuracy (Bicubic): {avg_bicubic:.2%}\")\n",
    "        print(f\"Average char accuracy (SR):      {avg_sr:.2%}\")\n",
    "        print(f\"Perfect plates (acc>0.99) HR: {hr_perfect}\")\n",
    "        print(f\"Perfect plates (acc>0.99) Bicubic: {bicubic_perfect}\")\n",
    "        print(f\"Perfect plates (acc>0.99) SR:      {sr_perfect}\")\n",
    "        print(\"=\" * 40)\n",
    "    else:\n",
    "        print(\"\\nNo images were evaluated.\")\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b37b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate OCR accuracy on:\n",
    "  1) Bicubic-upsampled LR images\n",
    "  2) Super-Resolution model outputs\n",
    "\n",
    "Metrics: character-level accuracy using Levenshtein distance.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from PIL import Image\n",
    "import Levenshtein\n",
    "\n",
    "from configs import SuperResolutionConfig, OCRConfig\n",
    "from modules.super_resolution import SuperResolutionInference\n",
    "from modules.ocr import OCRRecognizer\n",
    "\n",
    "\n",
    "def parse_xml_to_string(xml_path: Path, class_mapping) -> str | None:\n",
    "    \"\"\"\n",
    "    Parses a PASCAL VOC XML file, sorts characters by their horizontal position,\n",
    "    and returns the corresponding license plate string (mapped via class_mapping).\n",
    "    \"\"\"\n",
    "    if not xml_path.exists():\n",
    "        return None\n",
    "\n",
    "    tree = ET.parse(str(xml_path))\n",
    "    root = tree.getroot()\n",
    "\n",
    "    characters = []\n",
    "    for obj in root.findall(\"object\"):\n",
    "        class_name = obj.find(\"name\").text\n",
    "        xmin = int(obj.find(\"bndbox/xmin\").text)\n",
    "\n",
    "        mapped_name = class_mapping.get(class_name)\n",
    "        if mapped_name is None:\n",
    "            print(f\"Warning: Class '{class_name}' in {xml_path} not in CLASS_MAPPING. Skipping this char.\")\n",
    "            continue\n",
    "\n",
    "        characters.append((xmin, mapped_name))\n",
    "\n",
    "    if not characters:\n",
    "        return \"\"\n",
    "\n",
    "    characters.sort(key=lambda x: x[0])\n",
    "    return \"\".join([c[1] for c in characters])\n",
    "\n",
    "\n",
    "def calculate_character_accuracy(gt_string: str, pred_string: str) -> float:\n",
    "    \"\"\"\n",
    "    Character-level accuracy using Levenshtein distance:\n",
    "    Accuracy = (len(GT) - distance) / len(GT)\n",
    "    \"\"\"\n",
    "    if not gt_string:\n",
    "        return 0.0 if pred_string else 1.0\n",
    "\n",
    "    distance = Levenshtein.distance(gt_string, pred_string)\n",
    "    acc = (len(gt_string) - distance) / len(gt_string)\n",
    "    return max(0.0, acc)\n",
    "\n",
    "\n",
    "def main():\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Evaluate OCR accuracy on bicubic vs Super-Resolution outputs\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--lr-dir\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Directory with low-resolution plate images\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--hr-dir\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Directory with high-resolution plate images\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--xml-dir\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Directory with PASCAL VOC XML annotations for plates\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ocr-model\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Path to YOLOv8 OCR model (.pt)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--sr-model\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Path to Super-Resolution model weights (.pth)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--scale-factor\",\n",
    "        type=int,\n",
    "        default=8,\n",
    "        help=\"Upscaling factor for bicubic and SR model (must match SR model)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--device\",\n",
    "        type=str,\n",
    "        default=\"cuda\",\n",
    "        choices=[\"cuda\", \"cpu\"],\n",
    "        help=\"Device to use\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    lr_dir = Path(args.lr_dir)\n",
    "    hr_dir = Path(args.hr_dir)\n",
    "    xml_dir = Path(args.xml_dir)\n",
    "\n",
    "    # --- Set up SR inference (force apply to all images) ---\n",
    "    sr_config = SuperResolutionConfig(\n",
    "        model_path=args.sr_model,\n",
    "        device=args.device,\n",
    "        debug=False,\n",
    "        apply_threshold=False,  # apply SR to all images\n",
    "        scale_factor=args.scale_factor,\n",
    "    )\n",
    "    sr_infer = SuperResolutionInference(sr_config)\n",
    "\n",
    "    # --- Set up OCR recognizer ---\n",
    "    ocr_config = OCRConfig(\n",
    "        model_path=args.ocr_model,\n",
    "        device=args.device,\n",
    "        debug=False,\n",
    "    )\n",
    "    ocr = OCRRecognizer(ocr_config)\n",
    "    class_mapping = ocr_config.class_mapping\n",
    "\n",
    "    # --- Collect LR images ---\n",
    "    image_paths = []\n",
    "    for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.tif\", \"*.tiff\"):\n",
    "        image_paths.extend(glob.glob(str(lr_dir / ext)))\n",
    "    image_paths = sorted(image_paths)\n",
    "\n",
    "    if not image_paths:\n",
    "        print(f\"Error: No images found in '{lr_dir}'.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(image_paths)} LR images.\")\n",
    "\n",
    "    bicubic_accuracies = []\n",
    "    hr_accuracies = []\n",
    "    sr_accuracies = []\n",
    "    bicubic_perfect = 0\n",
    "    hr_perfect = 0\n",
    "    sr_perfect = 0\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        img_path = Path(img_path)\n",
    "        image_filename = img_path.name\n",
    "        hr_filename = img_path.stem + \".jpg\"\n",
    "        hr_path = hr_dir / hr_filename\n",
    "        xml_filename = img_path.stem + \".xml\"\n",
    "        xml_path = xml_dir / xml_filename\n",
    "\n",
    "        # --- Ground truth string from XML ---\n",
    "        gt_string = parse_xml_to_string(xml_path, class_mapping)\n",
    "        if gt_string is None:\n",
    "            print(f\"Warning: No XML found for {image_filename}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # --- Load LR image ---\n",
    "        lr_img = Image.open(img_path).convert(\"RGB\")\n",
    "        w, h = lr_img.size\n",
    "\n",
    "        hr_img = Image.open(hr_path).convert(\"RGB\")\n",
    "        hr_pred, _ = ocr.recognize(hr_img)\n",
    "        hr_acc = calculate_character_accuracy(gt_string, hr_pred)\n",
    "        hr_accuracies.append(hr_acc)\n",
    "        if hr_acc > 0.99:\n",
    "            hr_perfect += 1\n",
    "\n",
    "\n",
    "        # --- 1) Bicubic baseline upscaling ---\n",
    "        bicubic_img = lr_img.resize(\n",
    "            (w * args.scale_factor, h * args.scale_factor),\n",
    "            resample=Image.BICUBIC,\n",
    "        )\n",
    "\n",
    "        # --- 2) SR model upscaling ---\n",
    "        sr_img = sr_infer.enhance(lr_img)\n",
    "\n",
    "        # --- OCR on bicubic ---\n",
    "        bicubic_pred, _ = ocr.recognize(bicubic_img)\n",
    "        bicubic_acc = calculate_character_accuracy(gt_string, bicubic_pred)\n",
    "        bicubic_accuracies.append(bicubic_acc)\n",
    "        if bicubic_acc > 0.99:\n",
    "            bicubic_perfect += 1\n",
    "\n",
    "        # --- OCR on SR output ---\n",
    "        sr_pred, _ = ocr.recognize(sr_img)\n",
    "        sr_acc = calculate_character_accuracy(gt_string, sr_pred)\n",
    "        sr_accuracies.append(sr_acc)\n",
    "        if sr_acc > 0.99:\n",
    "            sr_perfect += 1\n",
    "\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Image: {image_filename}\")\n",
    "        print(f\"  GT:        {gt_string}\")\n",
    "        print(f\"  HR_Image:   {hr_pred}   (acc={hr_acc:.2%})\")\n",
    "        print(f\"  Bicubic:   {bicubic_pred}   (acc={bicubic_acc:.2%})\")\n",
    "        print(f\"  SR model:  {sr_pred}   (acc={sr_acc:.2%})\")\n",
    "\n",
    "    # --- Final summary ---\n",
    "    if bicubic_accuracies:\n",
    "        avg_hr = sum(hr_accuracies) / len(hr_accuracies)\n",
    "        avg_bicubic = sum(bicubic_accuracies) / len(bicubic_accuracies)\n",
    "        avg_sr = sum(sr_accuracies) / len(sr_accuracies)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 40)\n",
    "        print(\"EVALUATION COMPLETE\")\n",
    "        print(f\"Images evaluated: {len(bicubic_accuracies)}\")\n",
    "        print(f\"Average char accuracy (HR): {avg_hr:.2%}\")\n",
    "        print(f\"Average char accuracy (Bicubic): {avg_bicubic:.2%}\")\n",
    "        print(f\"Average char accuracy (SR):      {avg_sr:.2%}\")\n",
    "        print(f\"Perfect plates (acc>0.99) HR: {hr_perfect}\")\n",
    "        print(f\"Perfect plates (acc>0.99) Bicubic: {bicubic_perfect}\")\n",
    "        print(f\"Perfect plates (acc>0.99) SR:      {sr_perfect}\")\n",
    "        print(\"=\" * 40)\n",
    "    else:\n",
    "        print(\"\\nNo images were evaluated.\")\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
